{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他工具：Grab、PyQuery\n",
    "\n",
    "\n",
    "* 利用 Grab 套件的存取 HTML 資源\n",
    "* 利用 PyQuery 套件的解析 HTML 格式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "將之前用 requests + beatifulsoup 實作的方式，改寫成 grab + pyquery，並且比較有哪些地方不同。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grab in f:\\anaconda\\lib\\site-packages (0.6.41)\n",
      "Requirement already satisfied: six in c:\\users\\administrator\\appdata\\roaming\\python\\python37\\site-packages (from grab) (1.12.0)\n",
      "Requirement already satisfied: user-agent in f:\\anaconda\\lib\\site-packages (from grab) (0.1.9)\n",
      "Requirement already satisfied: defusedxml in f:\\anaconda\\lib\\site-packages (from grab) (0.6.0)\n",
      "Requirement already satisfied: weblib>=0.1.28 in f:\\anaconda\\lib\\site-packages (from grab) (0.1.30)\n",
      "Requirement already satisfied: selection in f:\\anaconda\\lib\\site-packages (from grab) (0.0.14)\n",
      "Requirement already satisfied: pytils in f:\\anaconda\\lib\\site-packages (from weblib>=0.1.28->grab) (0.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from pyquery import PyQuery as pq\n",
    "import logging\n",
    "from grab import Grab\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://google.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requests + BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"zh-TW\"><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"bqS7Wcd1U5kJO6wy5X35nw==\">(function(){window.google={kEI:'L6T4XaHjLZyEr7wP_LKluAw',kEXPI:'0,1353747,5662,731,223,3657,1069,379,206,467,438,2050,249,10,713,338,175,364,926,228,3,205,73,4,60,315,407,228,10,325,74,1129069,143,1197737,412,329118,1294,12383,4855,32691,15248,867,17444,11240,369,3314,5505,8384,1119,2,578,728,2432,1361,4323,4967,774,2250,2820,29,1902,3111,6196,1719,1808,1976,10953,5297,2054,622,298,873,1217,2975,2736,3694,7432,3874,2884,20,318,4147,1,150,1,217,2778,520,399,992,1285,8,85,2711,887,80,601,25,1279,390,1822,202,328,149,1943,324,193,318,1148,8,48,4258,260,52,1137,2,2669,1839,184,595,1182,520,257,1690,747,429,44,1009,93,328,1284,16,84,417,2426,1639,607,474,459,880,748,1039,604,2153,337\n",
      "\n",
      " <class 'bs4.BeautifulSoup'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"https://google.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "# My code\n",
    "\n",
    "# Requests\n",
    "r = requests.get(url)\n",
    "r.encoding = 'utf-8'\n",
    "print(r.text[0:1000])\n",
    "\n",
    "# BeautifulSoup\n",
    "soup = BeautifulSoup(url)\n",
    "print('\\n',type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab + PyQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My code\n",
    "\n",
    "# Grab \n",
    "g = Grab()\n",
    "resp = g.go(url)\n",
    "resp.body\n",
    "\n",
    "# PyQuery\n",
    "doc = pq(resp.body)\n",
    "title = doc('title')\n",
    "print(type(title), title.text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
